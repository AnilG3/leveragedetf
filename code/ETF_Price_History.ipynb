{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETF Data Collection\n",
    "\n",
    "Download prices for ETFs and populate database tables\n",
    "\n",
    "1. Download a master list of ETFs available. \n",
    "\n",
    "    - ETF.CSV file downloaded from GitHub repository https://github.com/paulperry/quant\n",
    "    - List of Leveraged ETF from https://stockmarketmba.com/listofleveragedetfs.php\n",
    "    - Various ETF lists downloaded from https://etfdb.com\n",
    "\n",
    "2. Retrieve all ETFs tickers.\n",
    "3. Retrieve price history of all valid ETFs and update *etf_history* database table\n",
    "4. [FUTURE]: Retrieve basic information of all valid ETFs and update *etf_info* database table. yfinance package is unreliable in retrieving basic information for ETFs. Look for another data source, possibly Alpaca.markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf # https://github.com/ranaroussi/yfinance\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Access remote SSH DB\n",
    "remote_db_flag = False\n",
    "\n",
    "if remote_db_flag:\n",
    "    from configparser import ConfigParser\n",
    "    import paramiko\n",
    "    from paramiko import SSHClient\n",
    "    from sshtunnel import SSHTunnelForwarder\n",
    "    \n",
    "    config = ConfigParser()\n",
    "    config.read('../private/config.ini')\n",
    "\n",
    "    # Config param\n",
    "    sql_hostname = config.get('mysqlDB', 'sql_hostname')\n",
    "    sql_username = config.get('mysqlDB', 'sql_username')\n",
    "    sql_password = config.get('mysqlDB', 'sql_password')\n",
    "    sql_main_database = config.get('mysqlDB', 'sql_main_database')\n",
    "    sql_port = config.getint('mysqlDB', 'sql_port')\n",
    "    ssh_host = config.get('sshC', 'ssh_host')\n",
    "    ssh_user = config.get('sshC', 'ssh_user')\n",
    "    ssh_password = config.get('sshC', 'ssh_password')\n",
    "    ssh_port = config.getint('sshC', 'ssh_port')\n",
    "    sql_ip = config.get('sshC', 'sql_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Extract Tickers from ETF file\n",
    "\"\"\"\n",
    "def get_tickers(data_path, ticker_file):\n",
    "    \n",
    "    # Import CSV file\n",
    "    df = pd.read_csv('{}/{}.csv'.format(data_path, ticker_file), index_col = 'Symbol')\n",
    "    \n",
    "    if ticker_file == 'ETF':\n",
    "        extract_keyword = '(Leveraged)'\n",
    "        # Filter leveraged ETFs, creates multiindex DF\n",
    "        lev_df = df.Category.str.extractall(extract_keyword)\n",
    "\n",
    "        # Access only ticker in multiindex and convert to list\n",
    "        file_tickers = lev_df.index.get_level_values(0).tolist()\n",
    "\n",
    "        invalid_ticker = set(['BGU', 'BRIL', 'BXDC', 'BXDD', 'CZI', \n",
    "                  'DXO', 'INDZ', 'KRU', 'MWJ', 'MWN', \n",
    "                  'RRY', 'SDK', 'SMK', 'TWOL', 'TWOZ',\n",
    "                  'TWQ', 'TYH', 'TYP', 'UKF', 'UKK',\n",
    "                  'UKW', 'UMM', 'UMX', 'UVG', 'UVU'\n",
    "                  'UWC'])\n",
    "\n",
    "        tickers = [x for x in file_tickers if x not in invalid_ticker]\n",
    "        \n",
    "    elif ticker_file in ['Leveraged_ETFs', 'etfs_details_type_fund_flow', \n",
    "                         'etfs_details_type_fund_flow-2', 'etfs_details_type_fund_flow-4',\n",
    "                        'etfs_details_type_fund_flow-9']:\n",
    "        \n",
    "        tickers = df.index.tolist()\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "# Test code, comment when not testing\n",
    "#tickers = get_tickers('../data/', 'etfs_details_type_fund_flow')\n",
    "#tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Get Tickers from DB for price update\n",
    "\"\"\"\n",
    "def get_tickers_from_db(db_table, ticker_fieldname):\n",
    "    \"\"\"\n",
    "        Gets list of tickers from input DB table\n",
    "        Input: DB table name\n",
    "        Output: List of tickers\n",
    "        [TBD] Exclude delisted tickers: RRZ, CZM, DMM, BRIS, UCD, TLL, DRR, URR, DTO, RTG, RHM, DPK, BXUB, BXUC, UXJ,\n",
    "        BGZ, RMS, SFK, RHO, RSU, FBND, FCOR, FLTB, KCNY, FLRT, RFN, LHB, RSW, IBD, OPER, IMLP, \n",
    "    \"\"\"\n",
    "    query = \"SELECT DISTINCT({}) FROM {};\".format(ticker_fieldname, db_table)\n",
    "    result = engine.execute(query)\n",
    "    tickers = [row[0] for row in result]\n",
    "    \n",
    "    return tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Import Price History for a Ticker\n",
    "\"\"\"\n",
    "# Import Price History for a Ticker\n",
    "# Multiple tickers can't be done simultaneously\n",
    "# as dates since when data is available might be different.\n",
    "\n",
    "def import_prices(ticker, db_table, dwnld_period='max'):\n",
    "    \n",
    "    if (ticker[-3:] == 'SIM'):\n",
    "        import_simulated_prices(ticker, db_table)\n",
    "    else:\n",
    "        \n",
    "        # Download historical data from Yahoo! Finance using yfinance\n",
    "        data = yf.download(ticker, period = dwnld_period)\n",
    "\n",
    "        # SQL insert statement\n",
    "        insert_init = \"\"\"INSERT INTO {} (trade_date, ticker, open, high, low, close, adj_close, volume) VALUES \"\"\".format(db_table)\n",
    "\n",
    "        # add values for all days to the insert statement\n",
    "        vals = \", \".join([\"\"\"('{}','{}', {}, {}, {}, {}, {}, {})\"\"\".format(str(day), ticker, row.Open, row.High, row.Low, row.Close, row['Adj Close'], row.Volume) for day, row in data.iterrows()])\n",
    "\n",
    "        # handle duplicates\n",
    "        insert_end = \"\"\" ON DUPLICATE KEY UPDATE open = VALUES(open), high = VALUES(high), low = VALUES(low), close = VALUES(close), adj_close = VALUES(adj_close), volume = VALUES(volume);\"\"\"\n",
    "\n",
    "        # put parts together\n",
    "        query = insert_init + vals + insert_end\n",
    "\n",
    "        result = engine.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Import Simulated Pricing for a Ticker\n",
    "\"\"\"\n",
    "# Attach SIM to ticker to keep them separate from the actual ticker price history.\n",
    "# Copy simulated prices to Open, High, Low, Close and Adj_Close.\n",
    "# Keep volume constant to 999,999 (easy identification in future)\n",
    "# update the prices after inception from actual ticker.\n",
    "# The SIM prices are created and saved as CSV by separate program\n",
    "# LETF_data_simulation\n",
    "\n",
    "def import_simulated_prices(ticker_sim, db_table):\n",
    "    \n",
    "    data_path = '../data/results'\n",
    "    volume = 999999\n",
    "    # Import CSV file\n",
    "    df = pd.read_csv('{}/{}.csv'.format(data_path, ticker_sim), header = 0, names = ['trade_date', 'close'], index_col = 'trade_date')\n",
    "    \n",
    "    # SQL insert statements\n",
    "    insert_init = \"\"\"INSERT INTO {} (trade_date, ticker, open, high, low, close, adj_close, volume) VALUES \"\"\".format(db_table)\n",
    "\n",
    "    # add values for all days to the insert statement\n",
    "    vals = \", \".join([\"\"\"('{}','{}', {}, {}, {}, {}, {}, {})\"\"\".format(str(day), ticker_sim, row.close, row.close, row.close, row.close, row.close, volume) for day, row in df.iterrows()])\n",
    "\n",
    "    # handle duplicates\n",
    "    insert_end = \"\"\" ON DUPLICATE KEY UPDATE open = VALUES(open), high = VALUES(high), low = VALUES(low), close = VALUES(close), adj_close = VALUES(adj_close), volume = VALUES(volume);\"\"\"\n",
    "\n",
    "    # put parts together\n",
    "    query = insert_init + vals + insert_end\n",
    "\n",
    "    result = engine.execute(query)\n",
    "    \n",
    "    # modify ticker for actual price retrieval\n",
    "    ticker = ticker_sim[:-3]\n",
    "    \n",
    "    # download historical data from Yahoo! Finance using yfinance\n",
    "    data = yf.download(ticker, period = 'max')\n",
    "    \n",
    "    # add values for all days to the insert statement\n",
    "    vals = \", \".join([\"\"\"('{}','{}', {}, {}, {}, {}, {}, {})\"\"\".format(str(day), ticker_sim, row.Open, row.High, row.Low, row.Close, row['Adj Close'], row.Volume) for day, row in data.iterrows()])\n",
    "\n",
    "    # handle duplicates\n",
    "    insert_end = \"\"\" ON DUPLICATE KEY UPDATE open = VALUES(open), high = VALUES(high), low = VALUES(low), close = VALUES(close), adj_close = VALUES(adj_close), volume = VALUES(volume);\"\"\"\n",
    "\n",
    "    # put parts together\n",
    "    query = insert_init + vals + insert_end\n",
    "    \n",
    "    result = engine.execute(query)\n",
    "    \n",
    "# For testing purpose, commented when not used\n",
    "# engine = create_engine(\"mysql+pymysql://root:root@127.0.0.1:8889/trading?unix_socket=/Applications/MAMP/tmp/mysql/mysql.sock\")\n",
    "# import_simulated_prices('TQQQSIM', 'etf_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tickers(ticker_file):\n",
    "    \n",
    "    # Data files path\n",
    "    data_path = '../data/'\n",
    "    \n",
    "    # Update specific tickers only\n",
    "    # set to empty to update all tickers in DB\n",
    "    #tickers = []\n",
    "    tickers = ['TQQQ', 'TMF', 'SPY', 'UPRO']\n",
    "    \n",
    "    if ticker_file:\n",
    "        # Update tickers from file\n",
    "        tickers = get_tickers(data_path, ticker_file)\n",
    "        db_table = 'etf_history'\n",
    "        # download maximum period available\n",
    "        dwnld_period = 'max'\n",
    "    else:\n",
    "        # retrieve tickers from DB\n",
    "        db_table = 'etf_history'\n",
    "        ticker_fieldname = 'ticker'\n",
    "        # Instead of downloading maximum period, just download last 3 months\n",
    "        dwnld_period = '3mo'\n",
    "        if not bool(tickers):\n",
    "            # tickers list is empty, fill from db\n",
    "            tickers = get_tickers_from_db(db_table, ticker_fieldname)\n",
    "    \n",
    "    # On Error, continue to next ticker\n",
    "    for ticker in tqdm(tickers, desc = 'Processing... ... ...'):\n",
    "        try:\n",
    "            import_prices(ticker, db_table, dwnld_period)\n",
    "        except Exception:\n",
    "            print(\"Couldn't retrieve ticker: {}\".format(ticker))\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remote_db_flag:\n",
    "    with SSHTunnelForwarder((ssh_host, ssh_port), ssh_username=ssh_user, ssh_password=ssh_password, remote_bind_address=(sql_hostname, sql_port)) as tunnel:\n",
    "        engine = create_engine('mysql+pymysql://%s:%s@127.0.0.1:%s/%s' % (sql_username, sql_password, tunnel.local_bind_port, sql_main_database), isolation_level = 'AUTOCOMMIT', echo = False)\n",
    "\n",
    "else:\n",
    "    engine = create_engine(\n",
    "    \"mysql+pymysql://root:root@127.0.0.1:8889/trading?unix_socket=/Applications/MAMP/tmp/mysql/mysql.sock\")\n",
    "\n",
    "# set ticker_file to False to update prices in DB\n",
    "process_tickers(ticker_file=False)\n",
    "\n",
    "# update ETF files\n",
    "#process_tickers('etfs_details_type_fund_flow-9')\n",
    "    \n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
