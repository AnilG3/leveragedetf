{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ETF Database Bundle for Zipline\n",
    "    \n",
    "    Save this file in \n",
    "    /opt/anaconda3/envs/zipline/lib/python3.5/site-packages/zipline/data/bundles/\n",
    "    extension.py is saved in ~/.zipline\n",
    "    \n",
    "    To ingest data:\n",
    "    Open a terminal window.\n",
    "    $conda activate zipline\n",
    "    zipline ingest -b etf_db_data\n",
    "\"\"\"\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# connect to DB\n",
    "engine = create_engine(\n",
    "    \"mysql+pymysql://root:root@127.0.0.1:8889/trading?unix_socket=/Applications/MAMP/tmp/mysql/mysql.sock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_etfs():\n",
    "    query = \"SELECT DISTINCT ticker FROM {} ORDER BY ticker\".format('etf_history')\n",
    "    tickers = pd.read_sql_query(query, engine)\n",
    "    # A list of tickers\n",
    "    return tickers.ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Ingest function needs to have this exact signature, meaning these arguments passed, as shown below.\n",
    "\"\"\"\n",
    "def etf_db_data(environ, asset_db_writer, minute_bar_writer, daily_bar_writer, adjustment_writer, calendar, start_session, end_session, cache, show_progress, output_dir):\n",
    "    \n",
    "    # Get list of available ETFs\n",
    "    symbols = available_etfs()\n",
    "    \n",
    "    # Prepare empty DF for dividends\n",
    "    divs = pd.DataFrame(columns=['sid', 'amount', 'ex_date', 'record_date', 'declared_date', 'pay_date'])\n",
    "    \n",
    "    # Prepare empty DF for splits\n",
    "    splits = pd.DataFrame(columns=['sid', 'ratio', 'effective_date'])\n",
    "    \n",
    "    # Prepare empty DF for metadata\n",
    "    metadata = pd.DataFrame(columns = ('start_date', 'end_date', 'auto_close_date', 'symbol', 'exchange'))\n",
    "    \n",
    "    # Check valid trading dates, according to selected exchange calendar\n",
    "    sessions = calendar.sessions_in_range(start_session, end_session)\n",
    "    \n",
    "    # Get data for all ETFs and write to Zipline\n",
    "    daily_bar_writer.write(process_stocks(symbols, sessions, metadata, divs))\n",
    "    \n",
    "    # Write metadata\n",
    "    asset_db_writer.write(equities = metadata)\n",
    "    \n",
    "    # Write splits and dividends\n",
    "    adjustment_writer.write(splits = splits, dividends = divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generator function to iterate ETFs, build historical data, metadata and dividend data\n",
    "\"\"\"\n",
    "def process_stocks(symbols, sessions, metadata, divs):\n",
    "    # Loop ETFs, setting a unique SID\n",
    "    sid = -1\n",
    "    for symbol in tqdm(symbols):\n",
    "        sid += 1\n",
    "        \n",
    "        # Make DB query\n",
    "        query = \"\"\"SELECT trade_date AS date, open, high, low, adj_close AS close, volume FROM {} WHERE ticker = '{}' ORDER BY trade_date;\"\"\".format('etf_history', symbol)\n",
    "        df = pd.read_sql_query(query, engine, index_col = 'date', parse_dates = ['date'])\n",
    "\n",
    "        # Check first and last date\n",
    "        start_date = df.index[0]\n",
    "        end_date = df.index[-1]\n",
    "\n",
    "        # Sync to official exchange calendar\n",
    "        df = df.reindex(sessions.tz_localize(None))[start_date: end_date]\n",
    "\n",
    "        # Forward fill missing data\n",
    "        df.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "        # Drop remaining NaN\n",
    "        df.dropna(inplace = True)\n",
    "\n",
    "        # Auto close date day after last trade\n",
    "        ac_date = end_date +pd.Timedelta(days = 1)\n",
    "\n",
    "        # Add row to metadata DF\n",
    "        metadata.loc[sid] = start_date, end_date, ac_date, symbol, 'NYSE'\n",
    "\n",
    "        # If there's dividend data, add to dividend DF\n",
    "        if 'dividend' in df.columns:\n",
    "            # slice off days with div\n",
    "            tmp = df[df['dividend'] != 0.0]['dividend']\n",
    "            div = pd.DataFrame(data = tmp.index.tolist(), columns = ['ex_date'])\n",
    "\n",
    "            # provide empty columns\n",
    "            div['record_date'] = pd.NaT\n",
    "            div['declared_date'] = pd.NaT\n",
    "            div['pay_date'] = pd.NaT\n",
    "\n",
    "            # start numbering at where left off last\n",
    "            ind = pd.index(range(divs.shape[0], divs.shape[0] + div.shape[0]))\n",
    "            div.set_index(ind, inplace=True)\n",
    "\n",
    "            # append ETF's dividend to list\n",
    "            divs = divs.append(div)\n",
    "        \n",
    "    yield sid, df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
